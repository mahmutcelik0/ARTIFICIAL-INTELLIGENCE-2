{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "versVj8nILer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Lambda, Input, Concatenate, Multiply\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras import callbacks\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "file_path = \"../DataSet/EXAMPLE_DATASET/result_to_neural_250.txt\"  # Dosya yolunu buraya göre ayarlayın\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9p5pZwRbj8n"
   },
   "outputs": [],
   "source": [
    "def read_input_file(file_path):\n",
    "    weights = []\n",
    "    values = []\n",
    "    capacities = []\n",
    "    best_picks = []\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(0, len(lines), 4):\n",
    "            # Okunan satırları boşluklarla ayrılan değerlere ayırarak diziye atama\n",
    "            value_line  = list(map(int, lines[i].split()))\n",
    "            weight_line = list(map(int, lines[i + 1].split()))\n",
    "            capacity_line = list(map(int, lines[i + 2].split()))\n",
    "            best_picks_line = list(map(int, lines[i + 3].split()))\n",
    "            \n",
    "\n",
    "            weights.append(weight_line)\n",
    "            values.append(value_line)\n",
    "            capacities.append(capacity_line)\n",
    "            best_picks.append(best_picks_line)\n",
    "\n",
    "    return weights, values, capacities, best_picks\n",
    "\n",
    "def create_knapsack_dataset(file_path, count,i):\n",
    "    weights, values, capacities, best_picks = read_input_file(file_path)\n",
    "    x = [[],[]]\n",
    "    y = [[]]\n",
    "    max_price = 0\n",
    "    max_weight = 0\n",
    "  \n",
    "    for i in range(count):\n",
    "        item_weights = weights[i]\n",
    "        item_values = values[i]\n",
    "        item_capacity = capacities[i]\n",
    "        item_count = len(item_weights)\n",
    "\n",
    "        # Max price ve max weight değerlerini güncelleme\n",
    "        max_price = max(max_price, np.max(item_values))\n",
    "        max_weight = max(max_weight, np.max(item_weights))\n",
    "\n",
    "\n",
    "        # Normalize prices ve weights hesaplama\n",
    "        normalized_prices = [price / max_price for price in item_values]\n",
    "        normalized_weights = [weight / max_weight for weight in item_weights]\n",
    "\n",
    "        # Capacity değerini normalize etme\n",
    "        normalized_capacity = item_capacity / max_weight\n",
    "        \n",
    "\n",
    "\n",
    "        x[0].append(normalized_weights)\n",
    "        x[1].append(normalized_prices)\n",
    "        #x[2].append(normalized_capacity)\n",
    "        y[0].append(best_picks[i])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64JJbqPlILet"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train = create_knapsack_dataset(file_path,9800,0)\n",
    "X_test, y_test = create_knapsack_dataset(file_path,200,9801)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QG8OCMaILeu"
   },
   "outputs": [],
   "source": [
    "def metric_overprice(input_prices):\n",
    "    def overpricing(y_true, y_pred):\n",
    "        y_pred = K.round(y_pred)\n",
    "        return K.mean(K.batch_dot(y_pred, input_prices, 1) - K.batch_dot(y_true, input_prices, 1))\n",
    "\n",
    "    return overpricing\n",
    "    \n",
    "def metric_space_violation(input_weights):\n",
    "    def space_violation(y_true, y_pred):\n",
    "        y_pred = K.round(y_pred)\n",
    "        return K.mean(K.maximum(K.batch_dot(y_pred, input_weights, 1) - 1, 0))\n",
    "    return space_violation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EcRn-7mILeu"
   },
   "outputs": [],
   "source": [
    "earlystopping = callbacks.EarlyStopping(monitor=\"loss\",\n",
    "                                        mode=\"min\", patience=5,\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "def train_knapsack(model,save_weights = False,model_name=\"first\" ):\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    import os\n",
    "    if save_weights:\n",
    "        model.fit(X_train, y_train, epochs=100, verbose=0, callbacks=[ModelCheckpoint(model_name+\".h5\", monitor=\"loss\", save_best_only=True, save_weights_only=True),earlystopping])\n",
    "    else :\n",
    "        model.load_weights(\"/content/\" + model_name + \".h5\")\n",
    "    train_results = model.evaluate(X_train, y_train, 100, 0)\n",
    "    test_results = model.evaluate(X_test, y_test, 100, 0);\n",
    "    print(\"Model results(Train/Test):\")\n",
    "    print(f\"Loss:               {train_results[0]:.2f} / {test_results[0]:.2f}\")\n",
    "    print(f\"Binary accuracy:    {train_results[1]:.2f} / {test_results[1]:.2f}\")\n",
    "    print(f\"Space violation:    {train_results[2]:.2f} / {test_results[2]:.2f}\")\n",
    "    print(f\"Overpricing:        {train_results[3]:.2f} / {test_results[3]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ui9MhrevILeu",
    "outputId": "548efdfc-1957-4f7f-89c2-df78bf81ceb1"
   },
   "outputs": [],
   "source": [
    "def supervised_continues_knapsack(item_count=5):\n",
    "    input_shape = (item_count,)\n",
    "    input_weights = Input(shape=input_shape)\n",
    "    input_prices = Input(shape=input_shape)\n",
    "    inputs_concat = Concatenate()([input_weights, input_prices])\n",
    "    picks = Dense(item_count, use_bias=False, activation=\"sigmoid\")(inputs_concat)\n",
    "    model = Model(inputs=[input_weights, input_prices], outputs=[picks])\n",
    "    model.compile(\"adam\",\n",
    "                  binary_crossentropy,\n",
    "                  metrics=[binary_accuracy, metric_space_violation(input_weights),\n",
    "                           metric_overprice(input_prices)])\n",
    "    return model\n",
    "model = supervised_continues_knapsack(250)\n",
    "train_knapsack(model,True,\"first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_Q5cV2AILev",
    "outputId": "beb46be3-a19a-406f-8509-589d7eb9c6d8"
   },
   "outputs": [],
   "source": [
    "def supervised_continues_knapsack_one_hidden(item_count=5):\n",
    "    input_weights = Input((item_count,))\n",
    "    input_prices = Input((item_count,))\n",
    "    input_capacity = Input((1,))\n",
    "    inputs_concat = Concatenate()([input_weights, input_prices])\n",
    "    picks = Dense(item_count * 10, use_bias=False, activation=\"sigmoid\")(inputs_concat)\n",
    "    picks = Dense(item_count, use_bias=False, activation=\"sigmoid\")(picks)\n",
    "    model = Model(inputs=[input_weights, input_prices], outputs=[picks])\n",
    "    model.compile(\"adam\",\n",
    "                  binary_crossentropy,\n",
    "                  metrics=[binary_accuracy, metric_space_violation(input_weights),\n",
    "                           metric_overprice(input_prices)])\n",
    "    return model\n",
    "model = supervised_continues_knapsack_one_hidden(250)\n",
    "train_knapsack(model,False,\"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bn0ijXHeILev",
    "outputId": "acc945ba-dc6f-4131-f57d-562f28260a72"
   },
   "outputs": [],
   "source": [
    "def supervised_discrete_knapsack(item_count=5):\n",
    "    input_weights = Input((item_count,))\n",
    "    input_prices = Input((item_count,))\n",
    "    input_capacity = Input((1,))\n",
    "    inputs_concat = Concatenate()([input_weights, input_prices])\n",
    "    concat_tanh = Dense(item_count, use_bias=False, activation=\"tanh\")(inputs_concat)\n",
    "    concat_sigmoid = Dense(item_count, use_bias=False, activation=\"sigmoid\")(inputs_concat)\n",
    "    concat_multiply = Multiply()([concat_sigmoid, concat_tanh])\n",
    "    picks = Multiply()([concat_multiply, concat_multiply])\n",
    "    model = Model(inputs=[input_weights, input_prices], outputs=[picks])\n",
    "    model.compile(\"sgd\",\n",
    "                  binary_crossentropy,\n",
    "                  metrics=[binary_accuracy, metric_space_violation(input_weights),\n",
    "                           metric_overprice(input_prices)])\n",
    "    return model\n",
    "\n",
    "model = supervised_discrete_knapsack(250)\n",
    "train_knapsack(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2Bw5_8nK8et"
   },
   "outputs": [],
   "source": [
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "def build_model(hp,item_count = 250):\n",
    "    input_shape = (item_count,)\n",
    "    input_weights = Input(shape=input_shape)\n",
    "    input_prices = Input(shape=input_shape)\n",
    "    inputs_concat = Concatenate()([input_weights, input_prices])\n",
    "    \n",
    "    hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.001, 0.01, 0.1], default=0.01)\n",
    "\n",
    "    dense_1 = Dense(hp_units, activation='relu')(inputs_concat)\n",
    "    picks = Dense(item_count, use_bias=False, activation=\"sigmoid\")(dense_1)\n",
    "    \n",
    "    model = Model(inputs=[input_weights, input_prices], outputs=[picks])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=hp_learning_rate),\n",
    "              loss=binary_crossentropy,\n",
    "              metrics=[binary_accuracy, metric_space_violation(input_weights),\n",
    "                       metric_overprice(input_prices)])\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner_directory',\n",
    "    project_name='knapsack_tuner'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=64, verbose=1)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n",
    "\n",
    "best_model.fit(X_train, y_train, epochs=50, batch_size=64, verbose=1)\n",
    "\n",
    "train_results = best_model.evaluate(X_train, y_train, batch_size=64)\n",
    "test_results = best_model.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "print(\"Model results (Train/Test):\")\n",
    "print(f\"Loss:               {train_results[0]:.2f} / {test_results[0]:.2f}\")\n",
    "print(f\"Binary accuracy:    {train_results[1]:.2f} / {test_results[1]:.2f}\")\n",
    "print(f\"Space violation:    {train_results[2]:.2f} / {test_results[2]:.2f}\")\n",
    "print(f\"Overpricing:        {train_results[3]:.2f} / {test_results[3]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
